{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to generate training/testing data from a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [3, 2, \"no\"],\n",
    "    [6, 6, \"yes\"],\n",
    "    [4, 1, \"no\"],\n",
    "    [4, 4, \"no\"],\n",
    "    [1, 2, \"yes\"],\n",
    "    [2, 0, \"no\"],\n",
    "    [0,3,\"yes\"],\n",
    "    [1,6,\"yes\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. holdout method\n",
    "1. random subsampling\n",
    "1. k fold cross validation\n",
    "1. bootstrap mmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. holdout method\n",
    "    * you \"hold out\" some instances from the dataset for testing\n",
    "    * train on the remaining instances\n",
    "    * test on the held out instances\n",
    "    * e.g. test_size=2 -> hold out 2 instances \n",
    "    * **NOTE**: You want to shuffle the dataset first, just to be sure the test set is not biased *(also seed before)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. random subsampling\n",
    "    * repeat the holdout method k tmes\n",
    "    * this is a different `k` from kNN\n",
    "        * so you can make a (kNN classifier with `k = 3`) on a (random subsampled dataset with `k = 10`)\n",
    "    * the accuracy is the average accuracy over the `k` holdout methods\n",
    "    * this removed the bias of the test set (see **note** above)\n",
    "    * for `k`:\n",
    "        * run holdout method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. k-fold cross validation\n",
    "    * more intentional about generating out the testing sets\n",
    "    * each instance is in the test set exactly one time\n",
    "    * create `k` folds (groups)\n",
    "    * for each fold in folds:\n",
    "        * hold out the fold for testing\n",
    "        * train on the remaining folds (folds - fold)\n",
    "    * accuracy is the (total correct) / (total predicted over **ALL** folds)\n",
    "    * when `k` doesnt go into `N` evenly, we stack the earlier folds to be larger than the later folds  \n",
    "        * LIKE DEALING CARDS IN A CARD GAME (give the leftover to the next repeat type)\n",
    "    * types:\n",
    "        * LOOCV leave one out cross validations\n",
    "            * k = N (the number of instances in the dataset)\n",
    "            * when do you use it?\n",
    "            *    when you have a small dataset and you need all the training data you can get\n",
    "            * train on N-1, test on 1\n",
    "        * stratified k fold cross validation\n",
    "            * where every fold has roughly the same distribution of class labels as the original set\n",
    "            * first, group by class\n",
    "            * for each group, distribute the instances to each fold\n",
    "                * like a card dealer\n",
    "                * NOTE: continue exactly where you left off! (for each group in groups)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Bootstrap method\n",
    "    * like random subsampling (2.) but with replacement (so you can get the same instance more than once)\n",
    "    * create a training set by sampling `N` instances with replacement\n",
    "    * ~63.2% will be sampled into your training set\n",
    "    * ~37.8% will not be sampled, and will end up in your test set\n",
    "        * this is called the out of bag sample\n",
    "    * repeat `k` times\n",
    "    * accuracy is the weighted average accuracy over the `k` samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0], [4, 2], [6, 3], [7, 5]]\n",
      "the training used against  [1, 0] will be  [[4, 2], [6, 3], [7, 5]]\n",
      "the training used against  [4, 2] will be  [[1, 0], [6, 3], [7, 5]]\n",
      "the training used against  [6, 3] will be  [[1, 0], [4, 2], [7, 5]]\n",
      "the training used against  [7, 5] will be  [[1, 0], [4, 2], [6, 3]]\n"
     ]
    }
   ],
   "source": [
    "# first we groupby\n",
    "yes = [1,4,6,7]\n",
    "no = [0,2,3,5]\n",
    "\n",
    "# now we create the folds\n",
    "# we want to split the data into 4 folds\n",
    "k = 4\n",
    "folds = []\n",
    "for i in range(k):\n",
    "    folds.append([])\n",
    "\n",
    "for i in range(len(yes)):\n",
    "    folds[i % k].append(yes[i])\n",
    "for i in range(len(no)):\n",
    "    folds[i % k].append(no[i])\n",
    "\n",
    "print(folds)\n",
    "\n",
    "for X_test in folds:\n",
    "    X_train = []\n",
    "    for i in range(len(folds)):\n",
    "        if folds[i] != X_test:\n",
    "            X_train.append(folds[i])\n",
    "    print(\"the training used against \", X_test, \"will be \", X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Classifier Performance\n",
    "* binary classification \n",
    "    * 2 class label\n",
    "    * e.g. pos/neg, good/bad, yes/no, etc.\n",
    "* multi-class classification\n",
    "    * 3 or more class labels\n",
    "    * pos/neg/neut, yes/no/maybe, etc. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $P$ = the # of positive instances in our test set  \n",
    "* $N$ = the # of negative instances in our test set  \n",
    "* $TP$ = the # of positive instances in our test set that were correctly classified  \n",
    "* $TN$ = the # of negative instances in our test set that were correctly classified  \n",
    "    * combined, these are our \"successful\" predictions ($TP$ + $TN$)\n",
    "* $FP$ (False Positives) = the # of negative instances in our test set that were incorrectly classified\n",
    "* $FN$ (False Negatives) = the # of positive instances in our test set that were incorrectly classified\n",
    "    * combined, these are our \"failed\" predictions ($FP$ + $FN$)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized confusion matrix for binary classification\n",
    "![](https://www.dataschool.io/content/images/2015/01/confusion_matrix2.png)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f8c5c8ab154ffd7b7cf769370d90abd279d12a3d937a702f83e9fc02204b3d3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
