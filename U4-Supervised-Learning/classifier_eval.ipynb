{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Rate\n",
    "Error Rate: 1 - accuracy\n",
    "$$ErrorRate = \\frac{FP + FN}{P + N}$$\n",
    "* Has same issues as accuracy (unbalanced labels)\n",
    "* For multi-class classification, can take the average error rate per class\n",
    "\n",
    "### Precision\n",
    "Precision (AKA positive predictive value): Proportion of instances classified as positive that are really positive\n",
    "$$Precision = \\frac{TP}{TP + FP}$$\n",
    "* A measure of \"exactness\"\n",
    "* When a classifier predicts positive, it is correct $precision$ percent of the time\n",
    "* A classifier with no false positives has a precision of 1\n",
    "\n",
    "### Recall\n",
    "Recall (AKA true positive rate (TPR) AKA sensitivity): The proportion of positive instances that are correctly classified as positive (e.g. labeled correctly)\n",
    "$$Recall = \\frac{TP}{P} = \\frac{TP}{TP + FN}$$\n",
    "* A measure of \"completeness\"\n",
    "* A classifier correctly classifies $recall$ percent of all positive cases\n",
    "* A classifier with no false negatives has a precision of 1\n",
    "* Used with the false positive rate to create receiver operator graphs and curves (ROC)\n",
    "\n",
    "### F1 Score \n",
    "F1-Score (AKA F-Measure): combines precision and recall via the harmonic mean of precision and recall:\n",
    "$$F = \\frac{2 \\times Precision \\times Recall}{Precision + Recall}$$\n",
    "* Summarizes a classifier in a single number (however, it is best practice to still investigate precision and recall, as well as other evaluation metrics)\n",
    "* Alternatively, we can weight precision:\n",
    "$$F_\\beta = \\frac{(1+\\beta^2) \\times Precision \\times Recall}{\\beta^2 \\times Precision + Recall}$$\n",
    "* Helps deal with class imbalance problem\n",
    "\n",
    "Note: Sci-kit Learn's [`classification_report()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) returns multi-class precision, recall, f1-score, and support given parallel lists of actual and predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Recall, and F-Measure for Multi-class Classification\n",
    "\"Micro\" average $\\mu$\n",
    "* Averaging the total true positives, false negatives and false positives\n",
    "    * E.g. compute TP and FP (or FN) over all the labels to compute precision (or recall))\n",
    "* Micro-averaging favors bigger classes\n",
    "\n",
    "$$Precision_\\mu = \\frac{\\sum_{i=1}^{L} TP_i}{\\sum_{i=1}^{L} (TP_i + FP_i)}$$\n",
    "\n",
    "$$Recall_\\mu = \\frac{\\sum_{i=1}^{L} TP_i}{\\sum_{i=1}^{L}(TP_i + FN_i)}$$\n",
    "\n",
    "$$F_\\mu = \\frac{2 \\times Precision_\\mu \\times Recall_\\mu}{Precision_\\mu + Recall_\\mu}$$\n",
    "\n",
    "\"Macro\" averaging $M$\n",
    "* Averaging the unweighted mean per label\n",
    "    * E.g. compute each label's precision (or recall) and average over number of labels\n",
    "* Macro-averaging treats all classes equally\n",
    "$$Precision_M = \\frac{\\sum_{i=1}^{L}\\frac{TP_i}{TP_i + FP_i}}{L}$$\n",
    "\n",
    "$$Recall_M = \\frac{\\sum_{i=1}^{L}\\frac{TP_i}{TP_i + FN_i}}{L}$$\n",
    "\n",
    "$$F_M = \\frac{\\sum_{i=1}^{L} \\frac{2 * Precision_{Mi} * Recall_{Mi}}{Precision_{Mi} + Recall_{Mi}}}{L}$$\n",
    "\n",
    "\"Weighted\" macro averaging $W$\n",
    "* Averaging the support-weighted mean per label\n",
    "    * E.g. like macro average, but compute each label's precision (or recall) then weight it by its count $P$ (AKA support) and average over the total number of instances\n",
    "$$Precision_W = \\frac{\\sum_{i=1}^{L}P_i \\times \\frac{TP_i}{TP_i + FP_i}}{P + N}$$\n",
    "\n",
    "$$Recall_W = \\frac{\\sum_{i=1}^{L}P_i \\times \\frac{TP_i}{TP_i + FN_i}}{P + N}$$\n",
    "\n",
    "$$F_W = \\frac{\\sum_{i=1}^{L} P_i \\times \\frac{2 * Precision_{Wi} * Recall_{Wi}}{Precision_{Wi} + Recall_{Wi}}}{P + N}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positive Rate \n",
    "False Positive Rate (FPR): The proportion of negative instances that are erroneously classified as positive\n",
    "$$False Positive Rate = \\frac{FP}{N} = \\frac{FP}{TN + FP}$$\n",
    "* Used with the true positive rate to create receiver operator graphs and curves (ROC)\n",
    "\n",
    "### False Negative Rate \n",
    "False Negative Rate (FNR): The proportion of positive instances that are erroneously classified as negative = 1 âˆ’ True Positive Rate\n",
    "$$False Negative Rate = \\frac{FN}{P} = \\frac{FN}{TP + FN}$$\n",
    "\n",
    "### True Negative Rate \n",
    "True Negative Rate (TNR AKA specificity): The proportion of negative instances that are correctly classified as negative\n",
    "$$False Negative Rate = \\frac{TN}{N} = \\frac{TN}{TN + FP}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicted\n",
    "||win|lose|total\n",
    "|---|---|---|---|\n",
    "win|18|2|20\n",
    "lose|12|8|20\n",
    "total|30|10|20\n",
    "\n",
    "acc = $\\frac{(TP + TN)}{P+N}$   \n",
    "\n",
    "acc = $\\frac{18 + 8} {40} = 0.65 == 65\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class classification\n",
    "\n",
    "||a|b|c|total|\n",
    "|---|---|---|---|---|\n",
    "a|$R_{}^{a}$|$R_{a}^{b}$|$R_{a}^{c}$|$R_{a}$|\n",
    "b|$R_{b}^{a}$|$R_{b}^{b}$|$R_{b}^{c}$|$R_{b}$\n",
    "c|$R_{c}^{a}$|$R_{c}^{b}$|$R_{c}^{c}$|$R_{c}$\n",
    "total|$R^{a}$|$R^{b}$|$R^{c}$|$R$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/full.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 1st approach (percent correctly classified):\n",
    "    * (20 + 15 + 18 + 12) / (105) = 62%\n",
    "2. 2nd approach (average accuracy per label)\n",
    "    * dry:\n",
    "        * $TP = 20$\n",
    "        * $FN = 5$ \n",
    "        * $FP = 5$\n",
    "        * $TN (Total - TP - FN - FP) = 75$\n",
    "        * AccDry = $\\frac{TP + TN}{Total}$ = (20+75)/105\n",
    "            * could also be written as $\\frac{Total - (FN + FP)}{Total}$ = (105 - (5+5)) / 105\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dry](images/dry.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|name|acc|\n",
    "|-|-|\n",
    "|AccDry = $\\frac{TP + TN}{Total}$ |90.4%  \n",
    "|AccSharp = $\\frac{TP + TN}{Total}$ |81.1%  \n",
    "|AccModerate = $\\frac{TP + TN}{Total}$ |81.9%  \n",
    "|AccDull = $\\frac{TP + TN}{Total}$ |70.4%  \n",
    "|total| 80.95%"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
